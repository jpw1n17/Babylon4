{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Flatten, Input, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "\n",
    "import h5py  # compress and save features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with h5py.File('features_train.h5', 'r') as f:\n",
    "    features = np.array(f['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244768, 9736)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with h5py.File('features_all_train.h5', 'r') as f:\n",
    "    feature_combine = np.array(f['feature_all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_combine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 666 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with h5py.File('features_salary.h5', 'r') as f:\n",
    "    salary = np.array(f['salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244768,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_log = np.log(salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with h5py.File('features_test.h5', 'r') as f:\n",
    "    feature_test = np.array(f['features_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122463, 9736)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**observe salary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_salay_dataset = pd.read_csv('./dataset/random_forest_benchmark_test_rev1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ture_salay = true_salay_dataset['SalaryNormalized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27394894f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1 = plt.figure(1)\n",
    "plt.hist(salary)\n",
    "plt.title('Orignal salary distribution')  \n",
    "plt.ylabel(\"Frequency\")  \n",
    "plt.xlabel(\"Salary\")\n",
    "# plt with same scale\n",
    "#plt.ylim(0,0.25)\n",
    "plt.xlim(0,110000)\n",
    "plt.savefig(\"Orignal salary distribution.PNG\", dpi = 600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It could find the distribution of salay is not Gauusian, therefore, take log to this data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2739492c048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make a histogram of the data array\n",
    "salary_log = np.log(salary)\n",
    " \n",
    "f1 = plt.figure(2)\n",
    "plt.hist(salary_log)\n",
    "plt.title('Log - salary distribution')  \n",
    "plt.ylabel(\"Frequency\")  \n",
    "plt.xlabel(\"Log - Salary\")\n",
    "# plt with same scale\n",
    "#plt.ylim(0,0.25)\n",
    "#plt.xlim(0,110000)\n",
    "plt.savefig(\"Log - salary distribution.PNG\", dpi = 600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroMean(dataMat):        \n",
    "    meanVal=np.mean(dataMat,axis=0)     #get mean by columns\n",
    "    newData=dataMat-meanVal  \n",
    "    return newData,meanVal\n",
    "\n",
    "\n",
    "def percentage2n(eigVals,percentage):  \n",
    "    sortArray=np.sort(eigVals)          #ascend order \n",
    "    sortArray=sortArray[-1::-1]           \n",
    "    arraySum=sum(sortArray)  \n",
    "    tmpSum=0  \n",
    "    num=0  \n",
    "    for i in sortArray:  \n",
    "        tmpSum+=i  \n",
    "        num+=1  \n",
    "        if tmpSum>=arraySum*percentage:  \n",
    "            return num  \n",
    "\n",
    "\n",
    "def pca(dataMat,percentage=0.99):  \n",
    "    newData,meanVal=zeroMean(dataMat)  \n",
    "    covMat=np.cov(newData,rowvar=0)      #covariance  \n",
    "    eigVals,eigVects=np.linalg.eig(np.mat(covMat))      \n",
    "    n=percentage2n(eigVals,percentage)                 #need n dimensionol data to get the convariance percentage\n",
    "    eigValIndice=np.argsort(eigVals)            #ascend order \n",
    "    n_eigValIndice=eigValIndice[-1:-(n+1):-1]   \n",
    "    n_eigVect=eigVects[:,n_eigValIndice]        \n",
    "    lowDDataMat=newData*n_eigVect               #lower dimensional data  \n",
    "    #reconMat=(lowDDataMat*n_eigVect.T)+meanVal  #reconstruct data  \n",
    "    return lowDDataMat,n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dimention too big to use this pca function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = features[0:122384]\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122384, 9736)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = features[122384:244768]\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = salary[0:122384]\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122384,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = salary[122384:244768]\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.log(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del features, salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 3000)              29211000  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1500)              4501500   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              1501000   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 35,214,501\n",
      "Trainable params: 35,214,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(3000,input_dim=9736, activation='relu',use_bias=True))\n",
    "#model.add(Dense(4000,input_dim=9736, activation='relu',use_bias=True)) # without fulldescription\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1500, activation='relu',use_bias=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation='relu',use_bias=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change log_dir for differnt activation function, change the number for every run.\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./tensorboard/3000-1500-1000-adam', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GTX960M  batch_size:1024  using around 50% of memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 195814 samples, validate on 48954 samples\n",
      "Epoch 1/100\n",
      " - 95s - loss: 22332891.1447 - val_loss: 12929.3978\n",
      "Epoch 2/100\n",
      " - 98s - loss: 13113.8887 - val_loss: 11914.2255\n",
      "Epoch 3/100\n",
      " - 101s - loss: 12033.5939 - val_loss: 10812.1000\n",
      "Epoch 4/100\n",
      " - 97s - loss: 10840.9043 - val_loss: 9724.7503\n",
      "Epoch 5/100\n",
      " - 98s - loss: 9771.0594 - val_loss: 8676.6102\n",
      "Epoch 6/100\n",
      " - 99s - loss: 8686.3623 - val_loss: 7690.3445\n",
      "Epoch 7/100\n",
      " - 98s - loss: 7703.1771 - val_loss: 6772.6240\n",
      "Epoch 8/100\n",
      " - 98s - loss: 6787.5582 - val_loss: 5940.2919\n",
      "Epoch 9/100\n",
      " - 95s - loss: 5953.6878 - val_loss: 5192.4488\n",
      "Epoch 10/100\n",
      " - 96s - loss: 5208.2251 - val_loss: 4525.9952\n",
      "Epoch 11/100\n",
      " - 98s - loss: 4538.9236 - val_loss: 3933.8009\n",
      "Epoch 12/100\n",
      " - 93s - loss: 3964.9334 - val_loss: 3414.9885\n",
      "Epoch 13/100\n",
      " - 95s - loss: 3438.1585 - val_loss: 2957.9668\n",
      "Epoch 14/100\n",
      " - 100s - loss: 2994.9079 - val_loss: 2560.5042\n",
      "Epoch 15/100\n",
      " - 94s - loss: 2597.9756 - val_loss: 2211.2572\n",
      "Epoch 16/100\n",
      " - 97s - loss: 2247.9089 - val_loss: 1911.4798\n",
      "Epoch 17/100\n",
      " - 98s - loss: 1947.1213 - val_loss: 1649.8525\n",
      "Epoch 18/100\n",
      " - 97s - loss: 1682.3103 - val_loss: 1422.4421\n",
      "Epoch 19/100\n",
      " - 94s - loss: 1452.7082 - val_loss: 1224.3254\n",
      "Epoch 20/100\n",
      " - 95s - loss: 1254.2035 - val_loss: 1054.6769\n",
      "Epoch 21/100\n",
      " - 100s - loss: 1080.9074 - val_loss: 907.1003\n",
      "Epoch 22/100\n",
      " - 95s - loss: 934.5783 - val_loss: 780.0652\n",
      "Epoch 23/100\n",
      " - 91s - loss: 803.5554 - val_loss: 670.2782\n",
      "Epoch 24/100\n",
      " - 93s - loss: 694.0541 - val_loss: 575.7167\n",
      "Epoch 25/100\n",
      " - 95s - loss: 596.6093 - val_loss: 494.0065\n",
      "Epoch 26/100\n",
      " - 96s - loss: 512.0300 - val_loss: 423.7353\n",
      "Epoch 27/100\n",
      " - 99s - loss: 442.3514 - val_loss: 362.5854\n",
      "Epoch 28/100\n",
      " - 94s - loss: 375.5538 - val_loss: 310.5231\n",
      "Epoch 29/100\n",
      " - 96s - loss: 323.1213 - val_loss: 265.7144\n",
      "Epoch 30/100\n",
      " - 96s - loss: 276.6870 - val_loss: 227.2151\n",
      "Epoch 31/100\n",
      " - 92s - loss: 236.3629 - val_loss: 193.9121\n",
      "Epoch 32/100\n",
      " - 89s - loss: 202.4405 - val_loss: 165.6557\n",
      "Epoch 33/100\n",
      " - 96s - loss: 173.3217 - val_loss: 141.4770\n",
      "Epoch 34/100\n",
      " - 94s - loss: 148.2449 - val_loss: 120.7061\n",
      "Epoch 35/100\n",
      " - 95s - loss: 125.2740 - val_loss: 102.8691\n",
      "Epoch 36/100\n",
      " - 92s - loss: 106.7819 - val_loss: 88.1391\n",
      "Epoch 37/100\n",
      " - 96s - loss: 81.7693 - val_loss: 18.3805\n",
      "Epoch 38/100\n",
      " - 94s - loss: 42.7823 - val_loss: 14.2072\n",
      "Epoch 39/100\n",
      " - 95s - loss: 39.3767 - val_loss: 12.7775\n",
      "Epoch 40/100\n",
      " - 92s - loss: 22.1430 - val_loss: 4.6044\n",
      "Epoch 41/100\n",
      " - 95s - loss: 3.3365 - val_loss: 4.7977\n",
      "Epoch 42/100\n",
      " - 91s - loss: 2.0234 - val_loss: 4.2538\n",
      "Epoch 43/100\n",
      " - 97s - loss: 1.5312 - val_loss: 4.3462\n",
      "Epoch 44/100\n",
      " - 94s - loss: 1.3520 - val_loss: 4.0717\n",
      "Epoch 45/100\n",
      " - 89s - loss: 1.2515 - val_loss: 3.8882\n",
      "Epoch 46/100\n",
      " - 96s - loss: 1.2917 - val_loss: 3.6883\n",
      "Epoch 47/100\n",
      " - 93s - loss: 1.2086 - val_loss: 4.1120\n",
      "Epoch 48/100\n",
      " - 91s - loss: 1.0602 - val_loss: 3.6842\n",
      "Epoch 49/100\n",
      " - 94s - loss: 1.0845 - val_loss: 3.9678\n",
      "Epoch 50/100\n",
      " - 91s - loss: 1.0384 - val_loss: 3.7369\n",
      "Epoch 51/100\n",
      " - 91s - loss: 0.9819 - val_loss: 3.7998\n",
      "Epoch 52/100\n",
      " - 94s - loss: 1.0788 - val_loss: 3.6644\n",
      "Epoch 53/100\n",
      " - 97s - loss: 0.9534 - val_loss: 3.7471\n",
      "Epoch 54/100\n",
      " - 96s - loss: 0.9663 - val_loss: 3.7705\n",
      "Epoch 55/100\n",
      " - 96s - loss: 0.9840 - val_loss: 3.5612\n",
      "Epoch 56/100\n",
      " - 95s - loss: 0.8970 - val_loss: 3.6885\n",
      "Epoch 57/100\n",
      " - 98s - loss: 0.8750 - val_loss: 4.2091\n",
      "Epoch 58/100\n",
      " - 92s - loss: 0.8654 - val_loss: 3.5392\n",
      "Epoch 59/100\n",
      " - 95s - loss: 0.8898 - val_loss: 3.5516\n",
      "Epoch 60/100\n",
      " - 90s - loss: 0.9591 - val_loss: 4.0375\n",
      "Epoch 61/100\n",
      " - 95s - loss: 0.9083 - val_loss: 3.9525\n",
      "Epoch 62/100\n",
      " - 97s - loss: 0.8003 - val_loss: 3.8499\n",
      "Epoch 63/100\n",
      " - 97s - loss: 0.8079 - val_loss: 3.5466\n",
      "Epoch 64/100\n",
      " - 81s - loss: 0.7890 - val_loss: 3.6844\n",
      "Epoch 65/100\n",
      " - 93s - loss: 0.7679 - val_loss: 3.1404\n",
      "Epoch 66/100\n",
      " - 97s - loss: 0.7842 - val_loss: 3.5327\n",
      "Epoch 67/100\n",
      " - 91s - loss: 0.7684 - val_loss: 3.2147\n",
      "Epoch 68/100\n",
      " - 93s - loss: 0.7510 - val_loss: 3.5430\n",
      "Epoch 69/100\n",
      " - 93s - loss: 0.7426 - val_loss: 3.3395\n",
      "Epoch 70/100\n",
      " - 93s - loss: 0.7322 - val_loss: 3.4373\n",
      "Epoch 71/100\n",
      " - 95s - loss: 0.7195 - val_loss: 3.0972\n",
      "Epoch 72/100\n",
      " - 93s - loss: 0.7177 - val_loss: 3.3734\n",
      "Epoch 73/100\n",
      " - 93s - loss: 0.7081 - val_loss: 3.2180\n",
      "Epoch 74/100\n",
      " - 93s - loss: 0.7015 - val_loss: 3.8208\n",
      "Epoch 75/100\n",
      " - 95s - loss: 0.6908 - val_loss: 3.4712\n",
      "Epoch 76/100\n",
      " - 93s - loss: 0.6843 - val_loss: 3.9058\n",
      "Epoch 77/100\n",
      " - 98s - loss: 0.7526 - val_loss: 3.3184\n",
      "Epoch 78/100\n",
      " - 93s - loss: 0.6718 - val_loss: 3.4753\n",
      "Epoch 79/100\n",
      " - 96s - loss: 0.6595 - val_loss: 3.3343\n",
      "Epoch 80/100\n",
      " - 96s - loss: 0.6631 - val_loss: 3.4703\n",
      "Epoch 81/100\n",
      " - 95s - loss: 0.6595 - val_loss: 3.8077\n",
      "Epoch 82/100\n",
      " - 88s - loss: 0.6539 - val_loss: 3.0962\n",
      "Epoch 83/100\n",
      " - 95s - loss: 0.6471 - val_loss: 3.2497\n",
      "Epoch 84/100\n",
      " - 83s - loss: 0.8476 - val_loss: 3.7701\n",
      "Epoch 85/100\n",
      " - 88s - loss: 0.6446 - val_loss: 3.2948\n",
      "Epoch 86/100\n",
      " - 90s - loss: 0.6380 - val_loss: 3.9910\n",
      "Epoch 87/100\n",
      " - 92s - loss: 0.6312 - val_loss: 3.4214\n",
      "Epoch 88/100\n",
      " - 86s - loss: 0.6275 - val_loss: 3.6881\n",
      "Epoch 89/100\n",
      " - 94s - loss: 0.6201 - val_loss: 3.3914\n",
      "Epoch 90/100\n",
      " - 88s - loss: 0.6211 - val_loss: 3.1971\n",
      "Epoch 91/100\n",
      " - 95s - loss: 0.6114 - val_loss: 3.1450\n",
      "Epoch 92/100\n",
      " - 95s - loss: 0.6145 - val_loss: 3.6283\n",
      "Epoch 93/100\n",
      " - 90s - loss: 0.6075 - val_loss: 3.3293\n",
      "Epoch 94/100\n",
      " - 95s - loss: 0.5997 - val_loss: 3.0739\n",
      "Epoch 95/100\n",
      " - 88s - loss: 0.6136 - val_loss: 3.0789\n",
      "Epoch 96/100\n",
      " - 89s - loss: 0.5940 - val_loss: 3.5131\n",
      "Epoch 97/100\n",
      " - 94s - loss: 0.5900 - val_loss: 3.0694\n",
      "Epoch 98/100\n",
      " - 92s - loss: 0.5990 - val_loss: 3.4108\n",
      "Epoch 99/100\n",
      " - 93s - loss: 0.5873 - val_loss: 2.8551\n",
      "Epoch 100/100\n",
      " - 94s - loss: 0.5878 - val_loss: 3.1120\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(features, salary_log, batch_size=1024, epochs=100, shuffle=True,verbose=2,validation_split=0.2, callbacks = [tbCallBack])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evalueate in test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "salay_predict = model.predict(feature_test)\n",
    "# obtain orignal salay\n",
    "salay_predict = np.exp(salay_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1708856e+14], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = 0\n",
    "for n in range(0,len(ture_salay)):\n",
    "    diff = abs(ture_salay[n] - salay_predict[n])\n",
    "    diff_square = np.square(diff)\n",
    "    mse = mse + diff_square\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result so bad**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding earlystopping, BatchNormalization AND Change to sgd opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4000, kernel_initializer=\"uniform\", input_dim=9736)`\n",
      "  app.launch_new_instance()\n",
      "E:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, kernel_initializer=\"uniform\")`\n",
      "E:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 4000)              38948000  \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4000)              16000     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              4001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 43,975,001\n",
      "Trainable params: 43,963,001\n",
      "Non-trainable params: 12,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(4000,input_dim=9736, init='uniform'))\n",
    "model.add(keras.layers.normalization.BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1000, init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1000, init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "# Compile model\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='min')\n",
    "# Change log_dir for differnt activation function, change the number for every run.\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./tensorboard/0', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 232529 samples, validate on 12239 samples\n",
      "Epoch 1/100\n",
      " - 110s - loss: 67.6266 - val_loss: 0.2725\n",
      "Epoch 2/100\n",
      " - 99s - loss: 0.2392 - val_loss: 0.2289\n",
      "Epoch 3/100\n",
      " - 96s - loss: 0.2321 - val_loss: 0.2251\n",
      "Epoch 4/100\n",
      " - 96s - loss: 0.2316 - val_loss: 0.2245\n",
      "Epoch 5/100\n",
      " - 97s - loss: 0.2316 - val_loss: 0.2241\n",
      "Epoch 6/100\n",
      " - 99s - loss: 0.2310 - val_loss: 0.2235\n",
      "Epoch 7/100\n",
      " - 99s - loss: 0.2307 - val_loss: 0.2230\n",
      "Epoch 8/100\n",
      " - 91s - loss: 0.2301 - val_loss: 0.2223\n",
      "Epoch 9/100\n",
      " - 97s - loss: 0.2297 - val_loss: 0.2216\n",
      "Epoch 10/100\n",
      " - 94s - loss: 0.2293 - val_loss: 0.2209\n",
      "Epoch 11/100\n",
      " - 95s - loss: 0.2287 - val_loss: 0.2204\n",
      "Epoch 12/100\n",
      " - 96s - loss: 0.2283 - val_loss: 0.2198\n",
      "Epoch 13/100\n",
      " - 94s - loss: 0.2280 - val_loss: 0.2194\n",
      "Epoch 14/100\n",
      " - 94s - loss: 0.2277 - val_loss: 0.2188\n",
      "Epoch 15/100\n",
      " - 95s - loss: 0.2272 - val_loss: 0.2182\n",
      "Epoch 16/100\n",
      " - 95s - loss: 0.2269 - val_loss: 0.2180\n",
      "Epoch 17/100\n",
      " - 88s - loss: 0.2257 - val_loss: 0.2153\n",
      "Epoch 18/100\n",
      " - 87s - loss: 0.2248 - val_loss: 0.2144\n",
      "Epoch 19/100\n",
      " - 99s - loss: 0.2240 - val_loss: 0.2134\n",
      "Epoch 20/100\n",
      " - 95s - loss: 0.2229 - val_loss: 0.2134\n",
      "Epoch 21/100\n",
      " - 97s - loss: 0.2227 - val_loss: 0.2127\n",
      "Epoch 22/100\n",
      " - 96s - loss: 0.2218 - val_loss: 0.2118\n",
      "Epoch 23/100\n",
      " - 97s - loss: 0.2208 - val_loss: 0.2104\n",
      "Epoch 24/100\n",
      " - 96s - loss: 0.2199 - val_loss: 0.2097\n",
      "Epoch 25/100\n",
      " - 96s - loss: 0.2193 - val_loss: 0.2090\n",
      "Epoch 26/100\n",
      " - 94s - loss: 0.2185 - val_loss: 0.2079\n",
      "Epoch 27/100\n",
      " - 86s - loss: 0.2174 - val_loss: 0.2064\n",
      "Epoch 28/100\n",
      " - 93s - loss: 0.2171 - val_loss: 0.2057\n",
      "Epoch 29/100\n",
      " - 99s - loss: 0.2162 - val_loss: 0.2045\n",
      "Epoch 30/100\n",
      " - 96s - loss: 0.2154 - val_loss: 0.2040\n",
      "Epoch 31/100\n",
      " - 95s - loss: 0.2146 - val_loss: 0.2029\n",
      "Epoch 32/100\n",
      " - 95s - loss: 0.2138 - val_loss: 0.2020\n",
      "Epoch 33/100\n",
      " - 94s - loss: 0.2132 - val_loss: 0.2011\n",
      "Epoch 34/100\n",
      " - 96s - loss: 0.2127 - val_loss: 0.2002\n",
      "Epoch 35/100\n",
      " - 92s - loss: 0.2117 - val_loss: 0.1993\n",
      "Epoch 36/100\n",
      " - 97s - loss: 0.2116 - val_loss: 0.1991\n",
      "Epoch 37/100\n",
      " - 86s - loss: 0.2111 - val_loss: 0.1982\n",
      "Epoch 38/100\n",
      " - 94s - loss: 0.2103 - val_loss: 0.1975\n",
      "Epoch 39/100\n",
      " - 95s - loss: 0.2099 - val_loss: 0.1968\n",
      "Epoch 40/100\n",
      " - 95s - loss: 0.2099 - val_loss: 0.1964\n",
      "Epoch 41/100\n",
      " - 96s - loss: 0.2092 - val_loss: 0.1960\n",
      "Epoch 42/100\n",
      " - 98s - loss: 0.2087 - val_loss: 0.1954\n",
      "Epoch 43/100\n",
      " - 96s - loss: 0.2086 - val_loss: 0.1951\n",
      "Epoch 44/100\n",
      " - 97s - loss: 0.2086 - val_loss: 0.1948\n",
      "Epoch 45/100\n",
      " - 94s - loss: 0.2078 - val_loss: 0.1938\n",
      "Epoch 46/100\n",
      " - 87s - loss: 0.2075 - val_loss: 0.1937\n",
      "Epoch 47/100\n",
      " - 93s - loss: 0.2073 - val_loss: 0.1939\n",
      "Epoch 48/100\n",
      " - 95s - loss: 0.2065 - val_loss: 0.1928\n",
      "Epoch 49/100\n",
      " - 97s - loss: 0.2064 - val_loss: 0.1926\n",
      "Epoch 50/100\n",
      " - 95s - loss: 0.2060 - val_loss: 0.1921\n",
      "Epoch 51/100\n",
      " - 100s - loss: 0.2057 - val_loss: 0.1918\n",
      "Epoch 52/100\n",
      " - 95s - loss: 0.2054 - val_loss: 0.1917\n",
      "Epoch 53/100\n",
      " - 95s - loss: 0.2053 - val_loss: 0.1917\n",
      "Epoch 54/100\n",
      " - 93s - loss: 0.2052 - val_loss: 0.1913\n",
      "Epoch 55/100\n",
      " - 94s - loss: 0.2048 - val_loss: 0.1909\n",
      "Epoch 56/100\n",
      " - 95s - loss: 0.2045 - val_loss: 0.1905\n",
      "Epoch 57/100\n",
      " - 94s - loss: 0.2041 - val_loss: 0.1899\n",
      "Epoch 58/100\n",
      " - 94s - loss: 0.2035 - val_loss: 0.1898\n",
      "Epoch 59/100\n",
      " - 94s - loss: 0.2037 - val_loss: 0.1893\n",
      "Epoch 60/100\n",
      " - 93s - loss: 0.2034 - val_loss: 0.1890\n",
      "Epoch 61/100\n",
      " - 94s - loss: 0.2034 - val_loss: 0.1889\n",
      "Epoch 62/100\n",
      " - 95s - loss: 0.2025 - val_loss: 0.1888\n",
      "Epoch 63/100\n",
      " - 93s - loss: 0.2024 - val_loss: 0.1880\n",
      "Epoch 64/100\n",
      " - 90s - loss: 0.2018 - val_loss: 0.1880\n",
      "Epoch 65/100\n",
      " - 93s - loss: 0.2017 - val_loss: 0.1875\n",
      "Epoch 66/100\n",
      " - 91s - loss: 0.2014 - val_loss: 0.1878\n",
      "Epoch 67/100\n",
      " - 91s - loss: 0.2017 - val_loss: 0.1875\n",
      "Epoch 68/100\n",
      " - 93s - loss: 0.2010 - val_loss: 0.1875\n",
      "Epoch 69/100\n",
      " - 95s - loss: 0.2006 - val_loss: 0.1872\n",
      "Epoch 70/100\n",
      " - 97s - loss: 0.2000 - val_loss: 0.1867\n",
      "Epoch 71/100\n",
      " - 101s - loss: 0.2000 - val_loss: 0.1866\n",
      "Epoch 72/100\n",
      " - 97s - loss: 0.1996 - val_loss: 0.1867\n",
      "Epoch 73/100\n",
      " - 97s - loss: 0.1992 - val_loss: 0.1862\n",
      "Epoch 74/100\n",
      " - 94s - loss: 0.1987 - val_loss: 0.1858\n",
      "Epoch 75/100\n",
      " - 92s - loss: 0.1987 - val_loss: 0.1860\n",
      "Epoch 76/100\n",
      " - 92s - loss: 0.1982 - val_loss: 0.1857\n",
      "Epoch 77/100\n",
      " - 97s - loss: 0.1981 - val_loss: 0.1854\n",
      "Epoch 78/100\n",
      " - 96s - loss: 0.1977 - val_loss: 0.1851\n",
      "Epoch 79/100\n",
      " - 96s - loss: 0.1967 - val_loss: 0.1850\n",
      "Epoch 80/100\n",
      " - 96s - loss: 0.1966 - val_loss: 0.1851\n",
      "Epoch 81/100\n",
      " - 96s - loss: 0.1969 - val_loss: 0.1847\n",
      "Epoch 82/100\n",
      " - 97s - loss: 0.1963 - val_loss: 0.1853\n",
      "Epoch 83/100\n",
      " - 97s - loss: 0.1953 - val_loss: 0.1845\n",
      "Epoch 84/100\n",
      " - 95s - loss: 0.1957 - val_loss: 0.1845\n",
      "Epoch 85/100\n",
      " - 98s - loss: 0.1946 - val_loss: 0.1847\n",
      "Epoch 86/100\n",
      " - 97s - loss: 0.1941 - val_loss: 0.1842\n",
      "Epoch 87/100\n",
      " - 94s - loss: 0.1939 - val_loss: 0.1834\n",
      "Epoch 88/100\n",
      " - 96s - loss: 0.1938 - val_loss: 0.1833\n",
      "Epoch 89/100\n",
      " - 97s - loss: 0.1932 - val_loss: 0.1836\n",
      "Epoch 90/100\n",
      " - 97s - loss: 0.1930 - val_loss: 0.1836\n",
      "Epoch 91/100\n",
      " - 96s - loss: 0.1924 - val_loss: 0.1838\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(features, salary_log, batch_size=1024, epochs=100, shuffle=True,verbose=2,validation_split=0.05, callbacks = [tbCallBack,early_stopping_monitor])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** It could find the early stopping used**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evalueate in test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 42.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "salay_predict = model.predict(feature_test)\n",
    "# obtain orignal salay\n",
    "salay_predict = np.exp(salay_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.09342409e+08])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = 0\n",
    "for n in range(0,len(ture_salay)):\n",
    "    diff = abs(ture_salay[n] - salay_predict[n])\n",
    "    diff_square = np.square(diff)\n",
    "    mse = mse + diff_square\n",
    "mse = mse/len(ture_salay)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average diff of predicted data is  [30.56017192] %\n"
     ]
    }
   ],
   "source": [
    "avrage_data = np.sqrt(mse)/np.mean(ture_salay)\n",
    "print('average diff of predicted data is ',avrage_data*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result still not good**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding earlystopping, BatchNormalization AND Change to adam opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
