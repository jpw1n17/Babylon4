{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_io\n",
    "from features import FeatureMapper, SimpleTransform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor():\n",
    "    features = [('FullDescription-Bag of Words', 'FullDescription', CountVectorizer(max_features=100)),\n",
    "                ('Title-Bag of Words', 'Title', CountVectorizer(max_features=100)),\n",
    "                ('LocationRaw-Bag of Words', 'LocationRaw', CountVectorizer(max_features=100)),\n",
    "                ('LocationNormalized-Bag of Words', 'LocationNormalized', CountVectorizer(max_features=100))]\n",
    "    combined = FeatureMapper(features)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline():\n",
    "    features = feature_extractor()\n",
    "    steps = [(\"extract_features\", features),\n",
    "             (\"classify\", BayesianRidge(alpha_1=1e-06, \n",
    "                                        alpha_2=1e-06, \n",
    "                                        compute_score=False, \n",
    "                                        copy_X=True,\n",
    "                                        fit_intercept=True, \n",
    "                                        lambda_1=1e-06, \n",
    "                                        lambda_2=1e-06, \n",
    "                                        n_iter=300,\n",
    "                                        tol=0.001, \n",
    "                                        verbose=True))]\n",
    "    return Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in the training data\n",
      "Extracting features and training model\n",
      "Convergence after  10  iterations\n",
      "Making predictions\n",
      "Writing predictions to file\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading in the training data\")\n",
    "train = data_io.get_train_df()\n",
    "\n",
    "print(\"Extracting features and training model\")\n",
    "classifier = get_pipeline()\n",
    "classifier.fit(train, train[\"SalaryNormalized\"])\n",
    "\n",
    "print(\"Making predictions\") \n",
    "valid = data_io.get_valid_df()\n",
    "predictions = classifier.predict(valid)   \n",
    "predictions = predictions.reshape(len(predictions), 1)\n",
    "\n",
    "print(\"Writing predictions to file\")\n",
    "data_io.write_submission(predictions)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence after  10  iterations\n",
      "Convergence after  10  iterations\n",
      "Convergence after  10  iterations\n",
      "Convergence after  10  iterations\n",
      "Convergence after  10  iterations\n",
      "Convergence after  10  iterations\n",
      "Convergence after  10  iterations\n",
      "Convergence after  10  iterations\n",
      "Convergence after  10  iterations\n",
      "Convergence after  10  iterations\n",
      "[-9298.87828195 -9844.93023152 -9382.66027581 -9493.33851091\n",
      " -9817.59724675 -9715.86945166 -9594.17281322 -9991.65019999\n",
      " -9705.29637546 -9782.10277655]\n"
     ]
    }
   ],
   "source": [
    "#10-fold cross-validation for mean error\n",
    "scores = cross_val_score(classifier, train, train[\"SalaryNormalized\"], cv=10, scoring='neg_mean_absolute_error')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = pd.read_csv('realsalary.csv')\n",
    "result = pd.read_csv('BayesianRidge_pre_rev1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 36750/36750 [00:01<00:00, 27488.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ME of this model is\n",
      "9641.277253591246\n"
     ]
    }
   ],
   "source": [
    "salary_real = real['SalaryNormalized']\n",
    "salary_result = result['SalaryNormalized']\n",
    "n = 0\n",
    "for i in tqdm(range(0,len(salary_real))):\n",
    "    n += abs(salary_real[i]-salary_result[i])\n",
    "n = n/len(salary_real)\n",
    "print('ME of this model is')\n",
    "print(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
